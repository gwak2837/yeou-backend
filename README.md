# ì¿ íŒ¡ ê°€ê²© ì•Œë¦¬ë¯¸

ì¿ íŒ¡, ë‹¤ë‚˜ì™€, ì˜¤ëŠ˜ì˜ì§‘

## ğŸ’» ê°œë°œ í™˜ê²½

- macOS 12.6
- [Node.js](https://nodejs.org/en/) 18.12
- [Yarn](https://yarnpkg.com/getting-started/install#install-corepack) 3.3
- [Git](https://git-scm.com/download) 2.38

## â˜ í´ë¼ìš°ë“œ

- [Vercel](https://vercel.com)
- [Google Cloud Run](https://cloud.google.com/run)
- [Google Cloud Storage](https://cloud.google.com/storage)
- [Google Cloud Build](https://cloud.google.com/build)
- [Google Container Registry](https://cloud.google.com/container-registry)
- [Oracle Virtual Machine](https://www.oracle.com/kr/cloud/compute/virtual-machines/)

## ğŸ“¦ ì„¤ì¹˜

### ì†ŒìŠ¤ì½”ë“œ ë‹¤ìš´ë¡œë“œ

í”„ë¡œì íŠ¸ ì†ŒìŠ¤ì½”ë“œë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³  ì˜ì¡´ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```
git clone https://github.com/rmfpdlxmtidl/jayudam-backend.git
cd jayudam-backend
yarn
```

### PostgreSQL ì„œë²„ ì‹¤í–‰

PostgreSQL ì„œë²„ë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ì´ 2ê°€ì§€ ìˆìŠµë‹ˆë‹¤.

#### 1. Docker í™˜ê²½

ì•„ë˜ëŠ” SSL ì—°ê²°ë§Œ í—ˆìš©í•˜ëŠ” ì„¤ì •ì…ë‹ˆë‹¤.

```bash
# set variables
POSTGRES_HOST=DBì„œë²„ì£¼ì†Œ
POSTGRES_USER=DBê³„ì •ì´ë¦„
POSTGRES_PASSWORD=DBê³„ì •ì•”í˜¸
POSTGRES_DB=DBì´ë¦„
POSTGRES_DOCKER_VOLUME_NAME=DBë„ì»¤ë³¼ë¥¨ì´ë¦„

# https://www.postgresql.org/docs/14/ssl-tcp.html
openssl req -new -nodes -text -out root.csr \
  -keyout root.key -subj "/CN=$POSTGRES_USER"

chmod og-rwx root.key

openssl x509 -req -in root.csr -text -days 3650 \
  -extfile /etc/ssl/openssl.cnf -extensions v3_ca \
  -signkey root.key -out root.crt

openssl req -new -nodes -text -out server.csr \
  -keyout server.key -subj "/CN=$POSTGRES_HOST"

openssl x509 -req -in server.csr -text -days 365 \
  -CA root.crt -CAkey root.key -CAcreateserial \
  -out server.crt

# https://stackoverflow.com/questions/55072221/deploying-postgresql-docker-with-ssl-certificate-and-key-with-volumes
sudo chown 0:70 server.key
sudo chmod 640 server.key

# https://www.postgresql.org/docs/14/auth-pg-hba-conf.html
echo "
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# 'local' is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            trust
# IPv6 local connections:
host    all             all             ::1/128                 trust
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            trust
host    replication     all             ::1/128                 trust

hostssl all all all scram-sha-256
" > pg_hba.conf

# start a postgres docker container, mapping the .key and .crt into the image.
sudo docker volume create $POSTGRES_DOCKER_VOLUME_NAME
sudo docker container create --name dummy-container --volume $POSTGRES_DOCKER_VOLUME_NAME:/root hello-world
sudo docker cp ./root.crt dummy-container:/root
sudo docker cp ./server.crt dummy-container:/root
sudo docker cp ./server.key dummy-container:/root
sudo docker cp ./pg_hba.conf dummy-container:/root
sudo docker rm dummy-container

sudo docker run \
  -d \
  -e POSTGRES_USER=$POSTGRES_USER \
  -e POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
  -e POSTGRES_DB=$POSTGRES_DB \
  -e LANG=ko_KR.UTF8 \
  -e LC_COLLATE=C \
  -e POSTGRES_INITDB_ARGS=--data-checksums \
  --name postgres \
  -p 5432:5432 \
  --restart=on-failure \
  --shm-size=256MB \
  --volume $POSTGRES_DOCKER_VOLUME_NAME:/var/lib/postgresql \
  postgres:14-alpine \
  -c ssl=on \
  -c ssl_ca_file=/var/lib/postgresql/root.crt \
  -c ssl_cert_file=/var/lib/postgresql/server.crt \
  -c ssl_key_file=/var/lib/postgresql/server.key \
  -c hba_file=/var/lib/postgresql/pg_hba.conf
```

ìœ„ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

- `pg_hba.conf`: PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë°©ì‹ ì„¤ì •
- `root.crt`: ë£¨íŠ¸ ì¸ì¦ì„œ. ì„œë²„ì—ì„œ ì‚¬ìš©. í´ë¼ì´ì–¸íŠ¸ ìª½ì— ë³µì‚¬
- `root.csr`: ?
- `root.key`: ë£¨íŠ¸/ë¦¬í”„ ì¸ì¦ì„œ ìƒì„± ì‹œ í•„ìš”. ìœ ì¸Œë˜ë©´ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•¨
- `server.crt`: ë¦¬í”„ ì¸ì¦ì„œ. ì„œë²„ì—ì„œ ì‚¬ìš©
- `server.csr`: ?
- `server.key`: ë¦¬í”„ ì¸ì¦ì„œ ìƒì„± ì‹œ í•„ìš”. ì„œë²„ì—ì„œ ì‚¬ìš©

ê·¸ë¦¬ê³  ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.

```
yarn import
```

#### 2. PostgreSQL í™˜ê²½

PostgreSQL ì„œë²„ì— ì ‘ì†í•´ì„œ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©ìì™€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. PostgreSQL ê¸°ë³¸ ê´€ë¦¬ì ì´ë¦„ì€ `postgres` ì…ë‹ˆë‹¤.

```sql
CREATE USER DB_ì‚¬ìš©ì_ì´ë¦„ WITH PASSWORD 'DB_ì‚¬ìš©ì_ë¹„ë°€ë²ˆí˜¸';
CREATE DATABASE DB_ì´ë¦„ OWNER DB_ì‚¬ìš©ì_ì´ë¦„ TEMPLATE template0 LC_COLLATE "C" LC_CTYPE "ko_KR.UTF-8";

\c DB_ì´ë¦„ DB_ê´€ë¦¬ì_ì´ë¦„
ALTER SCHEMA public OWNER TO DB_ì‚¬ìš©ì_ì´ë¦„;
```

ê·¸ë¦¬ê³  ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.

```
yarn import
```

### Redis ì„œë²„ ì‹¤í–‰

Redis ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
# https://redis.io/docs/manual/security/encryption/
git clone https://github.com/redis/redis.git
vi ./redis/utils/gen-test-certs.sh
```

ì¸ì¦ì„œì˜ CNì„ ìˆ˜ì •í•´ì¤ë‹ˆë‹¤.

```bash
# set variables
REDIS_USER=REDIS_ê³„ì •_ì´ë¦„
REDIS_PASSWORD=REDIS_ê³„ì •_ì•”í˜¸
REDIS_HOST=REDIS_ì£¼ì†Œ
REDIS_DOCKER_VOLUME_NAME=REDIS_ë„ì»¤_ë³¼ë¥¨_ì´ë¦„

# generate certificates
# https://github.com/redis/redis/blob/unstable/utils/gen-test-certs.sh
./redis/utils/gen-test-certs.sh $REDIS_HOST

echo "
user default off
user $REDIS_USER on >$REDIS_PASSWORD allkeys allchannels allcommands
" > users.acl

# https://github.com/moby/moby/issues/25245#issuecomment-365970076
sudo docker volume create $REDIS_DOCKER_VOLUME_NAME
sudo docker container create --name dummy-container -v $REDIS_DOCKER_VOLUME_NAME:/root hello-world
sudo docker cp ./tests/tls/server.crt dummy-container:/root
sudo docker cp ./tests/tls/server.key dummy-container:/root
sudo docker cp ./tests/tls/ca.crt dummy-container:/root
sudo docker cp ./tests/tls/redis.dh dummy-container:/root
sudo docker cp ./users.acl dummy-container:/root
sudo docker rm dummy-container

sudo docker run \
  --detach \
  -e REDIS_PASSWORD=redis \
  --name=redis \
  --publish 6379:6379 \
  --restart=on-failure \
  --volume $REDIS_DOCKER_VOLUME_NAME:/data \
  redis:7-alpine \
  redis-server \
  --loglevel warning \
  --tls-port 6379 --port 0 \
  --tls-cert-file /data/server.crt \
  --tls-key-file /data/server.key \
  --tls-ca-cert-file /data/ca.crt \
  --tls-dh-params-file /data/redis.dh \
  --appendonly yes --appendfsync no \
  --requirepass $REDIS_PASSWORD \
  --aclfile /data/users.acl
```

ê·¸ë¦¬ê³  ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¡œ Redis ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `client.crt`, `client.key`, `ca.crt` íŒŒì¼ì€ ì„œë²„ì—ì„œ ê°€ì ¸ì˜µë‹ˆë‹¤.

```bash
redis-cli \
  -h $REDIS_HOST \
  -p í¬íŠ¸ë²ˆí˜¸ \
  --user $REDIS_USER \
  --askpass \
  --tls \
  --cert ./client.crt \
  --key ./client.key \
  --cacert ./ca.crt
```

### í™˜ê²½ë³€ìˆ˜ ì œì‘

ë£¨íŠ¸ í´ë”ì— ì•„ë˜ì™€ ê°™ì€ ë‚´ìš©ì´ ë‹´ê¸´ í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜ ëª©ë¡ì€ [`src/common/constants.ts`](src/common/constants.ts) íŒŒì¼ ì•ˆì— ìˆìŠµë‹ˆë‹¤.

- `.env.local`: `yarn start` ì‹¤í–‰ ì‹œ í•„ìš”
- `.env.local.dev`: `yarn dev` ì‹¤í–‰ ì‹œ í•„ìš”
- `.env.local.docker`: `docker-compose up` ì‹¤í–‰ ì‹œ í•„ìš”
- `.env.test`: `yarn test` ì‹¤í–‰ ì‹œ í•„ìš”

### Node.js ì„œë²„ ì‹¤í–‰

Node.js ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ì´ 3ê°€ì§€ ìˆìŠµë‹ˆë‹¤.

1. Nodemonìœ¼ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```
yarn dev
```

2. esbuild íŒ¨í‚¤ì§€ë¡œ ë²ˆë“¤ë§ í›„ Node.jsë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```
yarn start
```

3. Docker í™˜ê²½ì—ì„œ Node.js ì„œë²„, PostgreSQL ì„œë²„, Redis ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```
docker-compose --env-file .env.local.docker up --detach --build --force-recreate
```

### CI/CD

GitHubì— push í•  ë•Œë§ˆë‹¤ ìë™ìœ¼ë¡œ `Cloud Build`ì—ì„œ ìƒˆë¡œìš´ Docker ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì„œ `Container Registry`ì— ì €ì¥í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  `Cloud Run`ì— ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Docker ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ‘¨â€ğŸ’» ê°œë°œ ê³¼ì •

### Yarn berry

> https://yarnpkg.com/getting-started/install

```bash
corepack enable
mkdir í´ë”ì´ë¦„
cd í´ë”ì´ë¦„
yarn init -2
```

### Git

> https://www.toptal.com/developers/gitignore

`.gitignore` íŒŒì¼ì„ ìƒì„±í•˜ê³  ì ì ˆíˆ ìˆ˜ì •í•©ë‹ˆë‹¤.

`.gitattributes` íŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì´ ìƒì„±í•©ë‹ˆë‹¤:

```
# Auto detect text files and perform LF normalization
* text eol=lf

# These files are binary and should be left untouched
*.png binary
*.jpg binary
*.jpeg binary
*.gif binary
*.ico binary
*.webp binary
*.pdf binary

*.otf binary
*.ttf binary
*.woff binary
*.woff2 binary

ê·¸ì™¸ ë°”ì´ë„ˆë¦¬ë¡œ ì·¨ê¸‰í•  íŒŒì¼ ëª©ë¡
```

### package.json

> https://docs.npmjs.com/cli/v8/configuring-npm/package-json

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "name": "í”„ë¡œì íŠ¸ ì´ë¦„",
  "version": "í”„ë¡œì íŠ¸ ë²„ì „",
  "description": "í”„ë¡œì íŠ¸ ì„¤ëª…",
  "homepage": "í™ˆí˜ì´ì§€ ì£¼ì†Œ",
  "bugs": {
    "url": "ë²„ê·¸ ì œë³´ ì£¼ì†Œ",
    "email": "ë²„ê·¸ ì œë³´ ì´ë©”ì¼"
  },
  "license": "ë¼ì´ì„ ìŠ¤",
  "author": "ê°œë°œì",
  "main": "í”„ë¡œê·¸ë¨ ì§„ì…ì  íŒŒì¼ ê²½ë¡œ",
  "repository": "ì €ì¥ì†Œ ì£¼ì†Œ",
  "scripts": {
    // ...
  },
  "dependencies": {
    // ...
  },
  "devDependencies": {
    // ...
  },
  "engines": {
    "node": ">=18.2.0"
  },
  "private": true,
  "packageManager": "yarn@3.3.0"
}
```

### TypeScript

> https://www.typescriptlang.org/download \
> https://stackoverflow.com/questions/72380007/what-typescript-configuration-produces-output-closest-to-node-js-18-capabilities/72380008#72380008

```bash
yarn add --dev typescript
yarn tsc --init
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  // ...
  "type": "module"
}
```

`tsconfig.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "compilerOptions": {
    // ...
    "allowSyntheticDefaultImports": true,
    "lib": ["ES2022"],
    "module": "ES2022",
    "moduleResolution": "node",
    "target": "ES2022"
  }
}
```

### Prettier

> https://prettier.io/docs/en/install.html

Prettierë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
yarn add --dev --exact prettier
echo {}> .prettierrc.json
```

`.prettierrc.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "printWidth": 100,
  "semi": false,
  "singleQuote": true
}
```

`.prettierignore` íŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì´ ìƒì„±í•©ë‹ˆë‹¤:

```
.yarn
.pnp.*
```

### ESLint

> https://eslint.org/docs/latest/user-guide/getting-started \
> https://github.com/standard/eslint-config-standard \
> https://github.com/import-js/eslint-plugin-import \
> https://github.com/weiran-zsd/eslint-plugin-node#readme \
> https://github.com/xjamundx/eslint-plugin-promise \

```bash
npm init @eslint/config -- --config standard
âœ” How would you like to use ESLint? Â· style
âœ” What type of modules does your project use? Â· esm
âœ” Which framework does your project use? Â· none
âœ” Does your project use TypeScript? Â· No / Yes
âœ” Where does your code run? Â· node
âœ” How would you like to define a style for your project? Â· guide
âœ” Which style guide do you want to follow? Â· standard
âœ” What format do you want your config file to be in? Â· JSON
Checking peerDependencies of eslint-config-standard@latest
Local ESLint installation not found.
The config that you've selected requires the following dependencies:

@typescript-eslint/eslint-plugin@latest eslint-config-standard@latest eslint@^8.0.1 eslint-plugin-import@^2.25.2 eslint-plugin-n@^15.0.0 eslint-plugin-promise@^6.0.0 @typescript-eslint/parser@latest
âœ” Would you like to install them now? Â· No

yarn add --dev @typescript-eslint/eslint-plugin@latest eslint-config-standard@latest eslint@^8.0.1 eslint-plugin-import@^2.25.2 eslint-plugin-n@^15.0.0 eslint-plugin-promise@^6.0.0 @typescript-eslint/parser@latest
```

`eslintrc.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "env": {
    "es2022": true,
    "node": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:import/recommended",
    "plugin:import/typescript",
    "plugin:n/recommended",
    "plugin:promise/recommended",
    "plugin:@typescript-eslint/recommended",
    "standard"
  ]
  // ...
}
```

### ESLint + (Prettier, Jest)

> https://github.com/prettier/eslint-config-prettier \
> https://github.com/jest-community/eslint-plugin-jest

```bash
yarn add --dev eslint eslint-plugin-jest eslint-config-prettier
```

`eslintrc.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "env": {
    // ...
    "jest/globals": true
  },
  "extends": [
    // ...
    // Make sure to put "prettier" last, so it gets the chance to override other configs
    "prettier"
  ],
  "overrides": [
    {
      "extends": ["plugin:jest/all"],
      "files": ["test/**"],
      "rules": {
        "jest/prefer-expect-assertions": "off"
      }
    }
  ]
  // ...
}
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "lint": "eslint . --fix --ignore-path .gitignore",
    "format": "prettier . --write"
    // ...
  }
  // ...
}
```

### Yarn berry + (ESLint, Prettier, TypeScript, VSCode, Next.js)

> https://yarnpkg.com/getting-started/editor-sdks \
> https://yarnpkg.com/cli/upgrade-interactive

```bash
yarn dlx @yarnpkg/sdks vscode
yarn plugin import interactive-tools
```

### Husky

> https://typicode.github.io/husky/#/?id=automatic-recommended \
> https://typicode.github.io/husky/#/?id=yarn-on-windows

Huskyë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
yarn dlx husky-init --yarn2 && yarn
```

`.husky/common.sh` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```sh
command_exists () {
  command -v "$1" >/dev/null 2>&1
}

# Workaround for Windows 10, Git Bash and Yarn
if command*exists winpty && test -t 1; then
  exec < /dev/tty
fi
```

`.husky/pre-push` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/*/husky.sh"
. "$(dirname -- "$0")/common.sh"

yarn tsc
```

### VSCode

`.vscode/settings.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "editor.defaultFormatter": "esbenp.prettier-vscode",
  "editor.formatOnPaste": true,
  "editor.formatOnSave": true,
  "editor.insertSpaces": true,
  "editor.tabSize": 2,
  "files.autoSave": "onFocusChange",
  "files.eol": "\n",
  "sort-imports.default-sort-style": "module"

  // ...
}
```

`.vscode/recommendations.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "recommendations": [
    "visualstudioexptteam.vscodeintellicode",
    "christian-kohler.npm-intellisense",
    "christian-kohler.path-intellisense",
    "tabnine.tabnine-vscode",
    "amatiasq.sort-imports",
    "ms-azuretools.vscode-docker",
    "bradymholt.pgformatter",
    "foxundermoon.shell-format",
    "ckolkman.vscode-postgres"

    // ...
  ]
}
```

### Environment variables

> https://github.com/motdotla/dotenv

```bash
yarn add dotenv
```

ì•„ë˜ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

| íŒŒì¼ ì´ë¦„           | `NODE_ENV`  | í™˜ê²½     | ìš©ë„            |
| ------------------- | ----------- | -------- | --------------- |
| `.env`              | production  | í´ë¼ìš°ë“œ | ì‹¤ ì„œë²„         |
| `.env.dev`          | production  | í´ë¼ìš°ë“œ | ìŠ¤í…Œì´ì§• ì„œë²„   |
| `.env.local`        | production  | ë¡œì»¬     | ì½”ë“œ ì¶•ì†Œ       |
| `.env.local.dev`    | development | ë¡œì»¬     | Fast refresh    |
| `.env.local.docker` | production  | ë¡œì»¬     | Docker ì»¨í…Œì´ë„ˆ |

`src/common/constants.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
// ìë™
export const NODE_ENV = process.env.NODE_ENV as string
export const K_SERVICE = process.env.K_SERVICE as string // GCPì—ì„œ ì‹¤í–‰ ì¤‘ì¼ ë•Œ
export const PORT = (process.env.PORT ?? '4000') as string

// ê³µí†µ
export const PROJECT_ENV = (process.env.PROJECT_ENV ?? '') as string
export const JWT_SECRET_KEY = process.env.JWT_SECRET_KEY as string

if (!PROJECT_ENV) throw new Error('`PROJECT_ENV` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
if (!JWT_SECRET_KEY) throw new Error('`JWT_SECRET_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')

// ê°œë³„
export const LOCALHOST_HTTPS_KEY = process.env.LOCALHOST_HTTPS_KEY as string
export const LOCALHOST_HTTPS_CERT = process.env.LOCALHOST_HTTPS_CERT as string

if (PROJECT_ENV.startsWith('local')) {
  if (!LOCALHOST_HTTPS_KEY) throw new Error('`LOCALHOST_HTTPS_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
  if (!LOCALHOST_HTTPS_CERT) throw new Error('`LOCALHOST_HTTPS_CERT` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
}
```

### Nodemon

> https://github.com/remy/nodemon

```bash
yarn add --dev nodemon
```

`nodemon.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "ext": "cjs",
  "watch": ["out"]
}
```

### esbuild

> https://esbuild.github.io/getting-started/#bundling-for-node \
> https://esbuild.github.io/api/#metafile \
> https://stackoverflow.com/a/35455532/16868717 \

```bash
yarn add --dev esbuild
```

`esbuild.js` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```js
import esbuild from 'esbuild'

const NODE_ENV = process.env.NODE_ENV

esbuild
  .build({
    bundle: true,
    entryPoints: ['src/index.ts'],
    loader: {
      '.sql': 'text',
    },
    metafile: true,
    minify: NODE_ENV === 'production',
    outfile: 'out/index.cjs',
    platform: 'node',
    target: ['node18'],
    treeShaking: true,
    watch: NODE_ENV === 'development' && {
      onRebuild: (error, result) => {
        if (error) {
          console.error('watch build failed:', error)
        } else {
          showOutfilesSize(result)
        }
      },
    },
  })
  .then((result) => showOutfilesSize(result))
  .catch((error) => {
    throw new Error(error)
  })

function showOutfilesSize(result) {
  const outputs = result.metafile.outputs
  for (const output in outputs) {
    console.log(`${output}: ${(outputs[output].bytes / 1_000_000).toFixed(2)} MB`)
  }
}
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "dev": "NODE_ENV=development node esbuild.js & NODE_ENV=development nodemon -r dotenv/config out/index.cjs dotenv_config_path=.env.local.dev",
    "build": "NODE_ENV=production node esbuild.js",
    "start": "yarn build && NODE_ENV=production node -r dotenv/config out/index.cjs dotenv_config_path=.env.local"
    // ...
  }
  // ...
}
```

`src/global-env.d.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
declare module '*.sql' {
  const content: string
  export default content
}
```

### Fastify

> https://www.fastify.io/docs/latest/Guides/Getting-Started/ \

```bash
yarn add fastify
```

`src/routes/index.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import Fastify from 'fastify'

import { K_SERVICE, NODE_ENV, PORT, PROJECT_ENV } from '../common/constants'
import productRoute from './product'
import userRoute from './user'

const fastify = Fastify({
  logger: NODE_ENV === 'production',
})

fastify.register(productRoute)
fastify.register(userRoute)

export default async function startServer() {
  try {
    await fastify.listen({ port: +PORT, host: K_SERVICE ? '0.0.0.0' : 'localhost' })
  } catch (err) {
    fastify.log.error(err)
    throw new Error()
  }
}
```

`.vscode/typescript.code-snippets` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "Fastify Routes": {
    "prefix": "route",
    "body": [
      "import { FastifyInstance } from 'fastify'",
      "",
      "export default async function routes(fastify: FastifyInstance, options: object) {",
      "  fastify.get('/${TM_FILENAME_BASE}', async (request, reply) => {",
      "    return { hello: '${TM_FILENAME_BASE}' }",
      "  })",
      "}",
      ""
    ],
    "description": "Fastify Routes"
  }
}
```

`src/routes/product.ts` íŒŒì¼ì„ ìƒì„±í•˜ê³  `route` ë‹¨ì¶•ì–´ë¥¼ ì…ë ¥í•´ ì•„ë˜ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•©ë‹ˆë‹¤:

```ts
import { FastifyInstance } from 'fastify'

export default async function routes(fastify: FastifyInstance, options: object) {
  fastify.get('/product', async (request, reply) => {
    return { hello: 'product' }
  })
}
```

`src/routes/user.ts` íŒŒì¼ì„ ìƒì„±í•˜ê³  `route` ë‹¨ì¶•ì–´ë¥¼ ì…ë ¥í•´ ì•„ë˜ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•©ë‹ˆë‹¤:

```ts
import { FastifyInstance } from 'fastify'

export default async function routes(fastify: FastifyInstance, options: object) {
  fastify.get('/user', async (request, reply) => {
    return { hello: 'user' }
  })
}
```

### Fastify + HTTP2

> https://www.fastify.io/docs/latest/Reference/HTTP2/

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import {
  // ...
  LOCALHOST_HTTPS_CERT,
  LOCALHOST_HTTPS_KEY,
  PROJECT_ENV,
} from '../common/constants'

const fastify = Fastify({
  // ...
  http2: true,
  ...(PROJECT_ENV.startsWith('local') && {
    https: {
      key: `-----BEGIN PRIVATE KEY-----\n${LOCALHOST_HTTPS_KEY}\n-----END PRIVATE KEY-----`,
      cert: `-----BEGIN CERTIFICATE-----\n${LOCALHOST_HTTPS_CERT}\n-----END CERTIFICATE-----`,
    },
  }),
})

// ...
```

HTTPS ì¸ì¦ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```bash

```

### Fastify + CORS

> https://github.com/fastify/fastify-cors

```bash
yarn add @fastify/cors
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import cors from '@fastify/cors'

// ...

fastify.register(cors, {
  origin: [
    'http://localhost:3000',
    // ...
  ],
})
```

### Fastify + Prevent DoS

> https://github.com/fastify/fastify-rate-limit

```bash
yarn add @fastify/rate-limit
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import rateLimit from '@fastify/rate-limit'

// ...

fastify.register(rateLimit, {
  ...(NODE_ENV === 'development' && {
    allowList: ['127.0.0.1'],
  }),
})
```

### Fastify + JWT

> https://github.com/fastify/fastify-jwt

```bash
yarn add @fastify/jwt
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import fastifyJWT from '@fastify/jwt'
import {
  // ...
  JWT_SECRET_KEY,
} from '../common/constants'

// ...

fastify.register(fastifyJWT, {
  secret: JWT_SECRET_KEY,
})

type QuerystringJWT = {
  Querystring: {
    jwt?: string
  }
}

fastify.addHook<QuerystringJWT>('onRequest', async (request, reply) => {
  const jwt = request.headers.authorization ?? request.query.jwt
  if (!jwt) return

  request.headers.authorization = jwt

  try {
    await request.jwtVerify()
  } catch (err) {
    reply.send(err)
  }
})
```

### Fastify + Schema

> https://www.fastify.io/docs/latest/Reference/Type-Providers/ \
> https://github.com/sinclairzx81/typebox \
> https://github.com/fastify/fastify-type-provider-typebox

```bash
yarn add @sinclair/typebox
yarn add --dev @fastify/type-provider-typebox
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import { TypeBoxTypeProvider } from '@fastify/type-provider-typebox'
import { Type } from '@sinclair/typebox'

// ...

const fastify = Fastify({
  // ...
}).withTypeProvider<TypeBoxTypeProvider>()

const schema = {
  schema: {
    querystring: Type.Object({
      foo: Type.Optional(Type.Number()),
      bar: Type.Optional(Type.String()),
    }),
    response: {
      200: Type.Object({
        hello: Type.String(),
        foo: Type.Optional(Type.Number()),
        bar: Type.Optional(Type.String()),
      }),
    },
  },
}

fastify.get('/', schema, async (request, _) => {
  const { foo, bar } = request.query
  return { hello: 'world', foo, bar }
})
```

### Fastify + Swagger

```bash
yarn add @fastify/swagger
```

### Fastify + Google Cloud File uploader

> https://github.com/fastify/fastify-multipart \
> https://github.com/googleapis/nodejs-storage#readme \
> https://cloud.google.com/storage/docs/reference/libraries#client-libraries-install-nodejs \
> https://cloud.google.com/storage/docs/uploading-objects-from-memory \
> https://cloud.google.com/storage/docs/streaming-uploads#code-samples

```bash
yarn add @fastify/multipart @google-cloud/storage
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import multipart from '@fastify/multipart'

// ..

fastify.register(multipart, {
  limits: {
    fileSize: 10_000_000,
    fieldSize: 1_000,
    files: 10,
  },
})
```

`src/routes/upload.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import { randomUUID } from 'crypto'
import path from 'path'

import { FastifyInstance } from 'fastify'

import { bucket } from '../common/google-storage'

type UploadResult = {
  fileName: string
  url: string
}

export default async function routes(fastify: FastifyInstance) {
  fastify.post('/upload/images', async function (request, reply) {
    // if (!request.userId) throw UnauthorizedError('ë¡œê·¸ì¸ í›„ ì‹œë„í•´ì£¼ì„¸ìš”')

    const files = request.files()
    const result: UploadResult[] = []

    for await (const file of files) {
      if (file.file) {
        // if (!file.mimetype.startsWith('image/'))
        //   throw BadRequestError('ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤')

        const timestamp = ~~(Date.now() / 1000)
        const fileExtension = path.extname(file.filename)
        const fileName = `${timestamp}-${randomUUID()}${fileExtension}`

        bucket
          .file(fileName)
          .save(await file.toBuffer())
          .then(() =>
            result.push({
              fileName: file.filename,
              url: `https://storage.googleapis.com/${bucket.name}/${fileName}`,
            })
          )
          .catch((error) => console.log(error))
      }
    }

    reply.status(201).send(result)
  })
}
```

`src/common/constants.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
// ...

export const GOOGLE_CLOUD_STORAGE_BUCKET_NAME = process.env
  .GOOGLE_CLOUD_STORAGE_BUCKET_NAME as string
```

### PostgreSQL

> https://node-postgres.com/ \
> https://pgtyped.vercel.app/docs/cli \
> https://stackoverflow.com/a/20909045/16868717 \
> https://github.com/brianc/node-postgres/issues/2089

```bash
yarn add pg
yarn add --dev @types/pg @pgtyped/cli @pgtyped/query
```

`src/common/constants.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
// ...
export const PGURI = process.env.PGURI as string
export const POSTGRES_CA = process.env.POSTGRES_CA as string
```

`src/common/postgres.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import pg from 'pg'

import { PGURI, POSTGRES_CA, PROJECT_ENV } from '../common/constants'

const { Pool } = pg

export const pool = new Pool({
  connectionString: PGURI,

  ...((PROJECT_ENV === 'cloud-dev' ||
    PROJECT_ENV === 'cloud-prod' ||
    PROJECT_ENV === 'local-prod') && {
    ssl: {
      ca: `-----BEGIN CERTIFICATE-----\n${POSTGRES_CA}\n-----END CERTIFICATE-----`,
      checkServerIdentity: () => {
        return undefined
      },
    },
  }),
})
```

`pgtyped.config.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "transforms": [
    {
      "mode": "sql",
      "include": "**/*.sql",
      "emitTemplate": "{{dir}}/{{name}}.ts"
    }
  ],
  "srcDir": "src/"
}
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤. `dev` ìŠ¤í¬ë¦½íŠ¸ê°€ ê¸¸ì–´ì§€ê¸° ë•Œë¬¸ì— ì•„ë˜ì²˜ëŸ¼ sh íŒŒì¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "dev": "src/dev.sh"
    // ...
  }
  // ...
}
```

`src/dev.sh` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```sh
#!/bin/sh
export $(grep -v '^#' .env.local.dev | xargs) && pgtyped --watch --config pgtyped.config.json &
sleep 2 && NODE_ENV=development node esbuild.js &
sleep 2 && NODE_ENV=development nodemon -r dotenv/config out/index.cjs dotenv_config_path=.env.local.dev
```

### PostgreSQL CSV

> https://www.postgresqltutorial.com/postgresql-tutorial/export-postgresql-table-to-csv-file/ \
> https://dba.stackexchange.com/q/137140 \
> https://github.com/brianc/node-pg-copy-streams

```bash
yarn add pg-copy-streams
yarn add --dev @types/pg-copy-streams
```

`database/index.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import dotenv from 'dotenv'
import pg from 'pg'

const { Pool } = pg

// í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
const env = process.argv[2]
export let CSV_PATH: string

if (env === 'prod') {
  dotenv.config()
  CSV_PATH = 'prod'
} else if (env === 'dev') {
  dotenv.config({ path: '.env.development' })
  CSV_PATH = 'dev'
} else {
  dotenv.config({ path: '.env.development.local' })
  CSV_PATH = 'local'
}

const PROJECT_ENV = process.env.PROJECT_ENV as string
const PGURI = process.env.PGURI as string
const POSTGRES_CA = process.env.POSTGRES_CA as string

if (!PROJECT_ENV) throw new Error('`PROJECT_ENV` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
if (!PGURI) throw new Error('`PGURI` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
if (!POSTGRES_CA) throw new Error('`POSTGRES_CA` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')

console.log(PGURI)

// PostgreSQL ì„œë²„ ì—°ê²°
export const pool = new Pool({
  connectionString: PGURI,

  ...((PROJECT_ENV === 'cloud-dev' ||
    PROJECT_ENV === 'cloud-prod' ||
    PROJECT_ENV === 'local-prod') && {
    ssl: {
      ca: `-----BEGIN CERTIFICATE-----\n${POSTGRES_CA}\n-----END CERTIFICATE-----`,
      checkServerIdentity: () => {
        return undefined
      },
    },
  }),
})
```

`database/export.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
/* eslint-disable no-console */
import { createWriteStream, mkdirSync, rmSync } from 'fs'
import { exit } from 'process'

import pgCopy from 'pg-copy-streams'

import { CSV_PATH, pool } from './index.js'

const { to } = pgCopy

// í´ë” ë‹¤ì‹œ ë§Œë“¤ê¸°
rmSync(`database/data/${CSV_PATH}`, { recursive: true, force: true })
mkdirSync(`database/data/${CSV_PATH}`, { recursive: true })

let fileCount = 0

const client = await pool.connect()

const { rows } = await client.query('SELECT schema_name FROM information_schema.schemata')

for (const row of rows) {
  const schemaName = row.schema_name
  if (schemaName !== 'pg_catalog' && schemaName !== 'information_schema') {
    const { rows: rows2 } = await client.query(
      `SELECT tablename FROM pg_tables WHERE schemaname='${schemaName}'`
    )

    for (const row2 of rows2) {
      const tableName = row2.tablename
      fileCount += 1
      console.log(`ğŸ‘€ - ${schemaName}.${tableName}`)

      const csvPath = `database/data/${CSV_PATH}/${schemaName}.${tableName}.csv`
      const fileStream = createWriteStream(csvPath)

      const sql = `COPY ${schemaName}.${tableName} TO STDOUT WITH CSV DELIMITER ',' HEADER ENCODING 'UTF-8'`
      const stream = client.query(to(sql))
      stream.pipe(fileStream)

      stream.on('end', () => {
        fileCount -= 1
        if (fileCount === 0) {
          client.release()
          exit()
        }
      })
    }
  }
}
```

`database/import.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
/* eslint-disable no-console */
import { createReadStream, readFileSync } from 'fs'
import { exit } from 'process'
import { createInterface } from 'readline'

import pgCopy from 'pg-copy-streams'

import { CSV_PATH, pool } from './index.js'

const { from } = pgCopy

const client = await pool.connect()

try {
  console.log('BEGIN')
  await client.query('BEGIN')

  const initialization = readFileSync('database/initialization.sql', 'utf8').toString()
  await client.query(initialization)

  // í…Œì´ë¸” ìƒì„± ìˆœì„œì™€ ë™ì¼í•˜ê²Œ
  const tables = [
    // ...
  ]

  // GENERATED ALWAYS AS IDENTITY ì»¬ëŸ¼ì´ ìˆëŠ” í…Œì´ë¸”
  const sequenceTables = [
    // ...
  ]

  for (const table of tables) {
    console.log('ğŸ‘€ - table', table)

    try {
      const csvPath = `database/data/${CSV_PATH}/${table}.csv`
      const columns = await readFirstLine(csvPath)
      const fileStream = createReadStream(csvPath)

      const sql = `COPY ${table}(${columns}) FROM STDIN WITH CSV DELIMITER ',' HEADER ENCODING 'UTF-8'`
      const stream = client.query(from(sql))
      fileStream.pipe(stream)
    } catch (error) {
      console.log('ğŸ‘€ - error', error)
    }
  }

  for (const sequenceTable of sequenceTables) {
    console.log('ğŸ‘€ - sequenceTable', sequenceTable)

    client.query(`LOCK TABLE ${sequenceTable} IN EXCLUSIVE MODE`)
    client.query(
      `SELECT setval(pg_get_serial_sequence('${sequenceTable}', 'id'), COALESCE((SELECT MAX(id)+1 FROM ${sequenceTable}), 1), false)`
    )
  }

  console.log('COMMIT')
  await client.query('COMMIT')
} catch (error) {
  console.log('ROLLBACK')
  await client.query('ROLLBACK')
  throw error
} finally {
  client.release()
}

exit()

// Utils
async function readFirstLine(path: string) {
  const inputStream = createReadStream(path)
  // eslint-disable-next-line no-unreachable-loop
  for await (const line of createInterface(inputStream)) return line
  inputStream.destroy()
}
```

`database/tsconfig.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "lib": ["ES2021"],
    "module": "ES2020",
    "moduleResolution": "node",
    "outDir": "dist",
    "allowSyntheticDefaultImports": true,
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "skipLibCheck": true
  },
  "include": ["./"]
}
```

`package.json` íŒŒì¼ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "export": "tsc --project database/tsconfig.json && node database/dist/export.js",
    "import": "tsc --project database/tsconfig.json && node database/dist/import.js"
    // ...
  }
  // ...
}
```

### Docker

### Docker Compose

### OAuth

### Jest ?
