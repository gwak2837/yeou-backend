# ì¿ íŒ¡ ê°€ê²© ì•Œë¦¬ë¯¸

ì¿ íŒ¡, ë‹¤ë‚˜ì™€, ì˜¤ëŠ˜ì˜ì§‘

## ğŸ’» ê°œë°œ í™˜ê²½

- macOS 12.6
- [Node.js](https://nodejs.org/en/) 18.12
- [Yarn](https://yarnpkg.com/getting-started/install#install-corepack) 3.3
- [Git](https://git-scm.com/download) 2.38

## â˜ í´ë¼ìš°ë“œ

- [Vercel](https://vercel.com)
- [Google Cloud Run](https://cloud.google.com/run)
- [Google Cloud Storage](https://cloud.google.com/storage)
- [Google Cloud Build](https://cloud.google.com/build)
- [Google Container Registry](https://cloud.google.com/container-registry)
- [Oracle Virtual Machine](https://www.oracle.com/kr/cloud/compute/virtual-machines/)

## ğŸ“¦ ì„¤ì¹˜

### ì†ŒìŠ¤ì½”ë“œ ë‹¤ìš´ë¡œë“œ

í”„ë¡œì íŠ¸ ì†ŒìŠ¤ì½”ë“œë¥¼ ë‹¤ìš´ë¡œë“œ ë°›ê³  ì˜ì¡´ íŒ¨í‚¤ì§€ë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```
git clone https://github.com/rmfpdlxmtidl/jayudam-backend.git
cd jayudam-backend
yarn
```

### Docker ì„¤ì¹˜

> https://docs.docker.com/engine/install/ubuntu/

```bash
sudo apt-get remove docker docker-engine docker.io containerd runc
sudo apt-get update
sudo apt-get install \
    ca-certificates \
    curl \
    gnupg \
    lsb-release
sudo mkdir -p /etc/apt/keyrings
curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg
echo \
  "deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \
  $(lsb_release -cs) stable" | sudo tee /etc/apt/sources.list.d/docker.list > /dev/null
sudo apt-get update
sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin
```

### PostgreSQL ì„œë²„ ì‹¤í–‰

PostgreSQL ì„œë²„ë¥¼ ì„¤ì •í•˜ëŠ” ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ì´ 2ê°€ì§€ ìˆìŠµë‹ˆë‹¤.

#### 1. Docker í™˜ê²½

ì•„ë˜ëŠ” SSL ì—°ê²°ë§Œ í—ˆìš©í•˜ëŠ” ì„¤ì •ì…ë‹ˆë‹¤.

```bash
# set variables
POSTGRES_HOST=DBì„œë²„ì£¼ì†Œ
POSTGRES_USER=DBê³„ì •ì´ë¦„
POSTGRES_PASSWORD=DBê³„ì •ì•”í˜¸
POSTGRES_DB=DBì´ë¦„

# https://www.postgresql.org/docs/14/ssl-tcp.html
openssl req -new -nodes -text -out root.csr \
  -keyout root.key -subj "/CN=$POSTGRES_USER"

chmod og-rwx root.key

openssl x509 -req -in root.csr -text -days 3650 \
  -extfile /etc/ssl/openssl.cnf -extensions v3_ca \
  -signkey root.key -out root.crt

openssl req -new -nodes -text -out server.csr \
  -keyout server.key -subj "/CN=$POSTGRES_HOST"

openssl x509 -req -in server.csr -text -days 365 \
  -CA root.crt -CAkey root.key -CAcreateserial \
  -out server.crt

# https://stackoverflow.com/questions/55072221/deploying-postgresql-docker-with-ssl-certificate-and-key-with-volumes
sudo chown 0:70 server.key
sudo chmod 640 server.key

# https://www.postgresql.org/docs/14/auth-pg-hba-conf.html
echo "
# TYPE  DATABASE        USER            ADDRESS                 METHOD

# 'local' is for Unix domain socket connections only
local   all             all                                     trust
# IPv4 local connections:
host    all             all             127.0.0.1/32            trust
# IPv6 local connections:
host    all             all             ::1/128                 trust
# Allow replication connections from localhost, by a user with the
# replication privilege.
local   replication     all                                     trust
host    replication     all             127.0.0.1/32            trust
host    replication     all             ::1/128                 trust

hostssl all all all scram-sha-256 clientcert=verify-ca
" > pg_hba.conf

# start a postgres docker container, mapping the .key and .crt into the image.
sudo docker volume create postgres-volume
sudo docker container create --name dummy-container --volume postgres-volume:/root hello-world
sudo docker cp ./root.crt dummy-container:/root
sudo docker cp ./server.crt dummy-container:/root
sudo docker cp ./server.key dummy-container:/root
sudo docker cp ./pg_hba.conf dummy-container:/root
sudo docker rm dummy-container

sudo docker run \
  -d \
  -e POSTGRES_USER=$POSTGRES_USER \
  -e POSTGRES_PASSWORD=$POSTGRES_PASSWORD \
  -e POSTGRES_DB=$POSTGRES_DB \
  -e LANG=ko_KR.UTF8 \
  -e LC_COLLATE=C \
  -e POSTGRES_INITDB_ARGS=--data-checksums \
  --name postgres \
  -p 5432:5432 \
  --restart=on-failure \
  --shm-size=256MB \
  --volume postgres-volume:/var/lib/postgresql \
  postgres:14-alpine \
  -c ssl=on \
  -c ssl_ca_file=/var/lib/postgresql/root.crt \
  -c ssl_cert_file=/var/lib/postgresql/server.crt \
  -c ssl_key_file=/var/lib/postgresql/server.key \
  -c hba_file=/var/lib/postgresql/pg_hba.conf

sudo docker ps -a
sudo docker volume ls
```

ìœ„ ëª…ë ¹ì–´ë¥¼ ì‹¤í–‰í•˜ë©´ ì•„ë˜ì™€ ê°™ì€ íŒŒì¼ì´ ìƒì„±ë©ë‹ˆë‹¤.

- `pg_hba.conf`: PostgreSQL í´ë¼ì´ì–¸íŠ¸ ì—°ê²° ë°©ì‹ ì„¤ì •
- `root.crt`: ë£¨íŠ¸ ì¸ì¦ì„œ. í´ë¼ì´ì–¸íŠ¸ë¡œ ë³µì‚¬
- `root.csr`: ?
- `root.key`: ë£¨íŠ¸/ë¦¬í”„ ì¸ì¦ì„œ ìƒì„± ì‹œ í•„ìš”. ìœ ì¸Œë˜ë©´ ìƒˆë¡œ ë§Œë“¤ì–´ì•¼ í•¨
- `server.crt`: ë¦¬í”„ ì¸ì¦ì„œ. í´ë¼ì´ì–¸íŠ¸ë¡œ ë³µì‚¬
- `server.csr`: ?
- `server.key`: ë¦¬í”„ ì¸ì¦ì„œ ìƒì„± ì‹œ í•„ìš”. í´ë¼ì´ì–¸íŠ¸ë¡œ ë³µì‚¬

ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì•„ë˜ ëª…ë ¹ì–´ë¡œ PostgreSQL ì„œë²„ ì ‘ì†ì„ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤:

```bash
psql "postgresql://ì•„ì´ë””:ë¹„ë°€ë²ˆí˜¸@ì„œë²„ì£¼ì†Œ:ì„œë²„í¬íŠ¸/ì´ë¦„?sslmode=verify-full&sslrootcert=ë£¨íŠ¸ì¸ì¦ì„œìœ„ì¹˜&sslcert=ë¦¬í”„ì¸ì¦ì„œìœ„ì¹˜&sslkey=ë¦¬í”„ì¸ì¦ì„œí‚¤ìœ„ì¹˜"
```

ê·¸ë¦¬ê³  ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.

```
yarn import
```

#### 2. PostgreSQL í™˜ê²½

PostgreSQL ì„œë²„ì— ì ‘ì†í•´ì„œ ì•„ë˜ì™€ ê°™ì´ ì‚¬ìš©ìì™€ ë°ì´í„°ë² ì´ìŠ¤ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. PostgreSQL ê¸°ë³¸ ê´€ë¦¬ì ì´ë¦„ì€ `postgres` ì…ë‹ˆë‹¤.

```sql
CREATE USER ì‚¬ìš©ìì´ë¦„ WITH PASSWORD 'ì‚¬ìš©ìë¹„ë°€ë²ˆí˜¸';
\du
CREATE DATABASE DBì´ë¦„ OWNER ì‚¬ìš©ìì´ë¦„ TEMPLATE template0 LC_COLLATE "C" LC_CTYPE "ko_KR.UTF-8";
\l
\c DBì´ë¦„ DBê´€ë¦¬ìì´ë¦„
ALTER SCHEMA public OWNER TO ì‚¬ìš©ìì´ë¦„;
\dn
```

ê·¸ë¦¬ê³  ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ì‹¤í–‰í•˜ê±°ë‚˜ ìˆ˜ë™ìœ¼ë¡œ ë°ì´í„°ë² ì´ìŠ¤ì— ë”ë¯¸ ë°ì´í„°ë¥¼ ë„£ì–´ì¤ë‹ˆë‹¤.

```
yarn import
```

### Redis ì„œë²„ ì‹¤í–‰

ì¸ì¦ì„œì˜ O(Organization), CN(Common Name)ì„ ìˆ˜ì •í•´ì¤ë‹ˆë‹¤.

```bash
# https://redis.io/docs/manual/security/encryption/
git clone https://github.com/redis/redis.git
vi ./redis/utils/gen-test-certs.sh
```

Redis ì¸ì¦ì„œë¥¼ ë§Œë“¤ê³  ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```bash
# set variables
REDIS_USER=REDIS_ê³„ì •_ì´ë¦„
REDIS_PASSWORD=REDIS_ê³„ì •_ì•”í˜¸
REDIS_HOST=REDIS_ì£¼ì†Œ
REDIS_DOCKER_VOLUME_NAME=REDIS_ë„ì»¤_ë³¼ë¥¨_ì´ë¦„

# generate certificates
# https://github.com/redis/redis/blob/unstable/utils/gen-test-certs.sh
./redis/utils/gen-test-certs.sh $REDIS_HOST

echo "
user default off
user $REDIS_USER on >$REDIS_PASSWORD allkeys allchannels allcommands
" > users.acl

# https://github.com/moby/moby/issues/25245#issuecomment-365970076
sudo docker volume create $REDIS_DOCKER_VOLUME_NAME
sudo docker container create --name dummy-container -v $REDIS_DOCKER_VOLUME_NAME:/root hello-world
sudo docker cp ./tests/tls/server.crt dummy-container:/root
sudo docker cp ./tests/tls/server.key dummy-container:/root
sudo docker cp ./tests/tls/ca.crt dummy-container:/root
sudo docker cp ./tests/tls/redis.dh dummy-container:/root
sudo docker cp ./users.acl dummy-container:/root
sudo docker rm dummy-container
sudo docker image rm hello-world

sudo docker run \
  --detach \
  -e REDIS_PASSWORD=redis \
  --name=redis \
  --publish 6379:6379 \
  --restart=on-failure \
  --volume $REDIS_DOCKER_VOLUME_NAME:/data \
  redis:7-alpine \
  redis-server \
  --loglevel warning \
  --tls-port 6379 --port 0 \
  --tls-cert-file /data/server.crt \
  --tls-key-file /data/server.key \
  --tls-ca-cert-file /data/ca.crt \
  --tls-dh-params-file /data/redis.dh \
  --appendonly yes --appendfsync no \
  --requirepass $REDIS_PASSWORD \
  --aclfile /data/users.acl

sudo docker ps -a
```

ê·¸ë¦¬ê³  ë¡œì»¬ ì»´í“¨í„°ì—ì„œ ì•„ë˜ì™€ ê°™ì€ ëª…ë ¹ì–´ë¡œ í´ë¼ìš°ë“œì— ìˆëŠ” Redis ì„œë²„ì— ì ‘ì†í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤. `client.crt`, `client.key`, `ca.crt` íŒŒì¼ì€ í´ë¼ìš°ë“œ ì„œë²„ì—ì„œ SFTPë¥¼ ì´ìš©í•´ ë¡œì»¬ ì»´í“¨í„°ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤.

```bash
redis-cli \
  -h $REDIS_HOST \
  -p í¬íŠ¸ë²ˆí˜¸ \
  --user $REDIS_USER \
  --askpass \
  --tls \
  --cert ./client.crt \
  --key ./client.key \
  --cacert ./ca.crt
```

### í™˜ê²½ë³€ìˆ˜ ì„¤ì •

ë£¨íŠ¸ í´ë”ì— ì•„ë˜ì™€ ê°™ì€ ë‚´ìš©ì´ ë‹´ê¸´ í™˜ê²½ ë³€ìˆ˜ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤.

í•„ìš”í•œ í™˜ê²½ë³€ìˆ˜ ëª©ë¡ì€ [`src/common/constants.ts`](src/common/constants.ts) íŒŒì¼ ì•ˆì— ìˆìŠµë‹ˆë‹¤.

- `.env.local`: `yarn start` ì‹¤í–‰ ì‹œ í•„ìš”
- `.env.local.dev`: `yarn dev` ì‹¤í–‰ ì‹œ í•„ìš”
- `.env.local.docker`: `docker-compose up` ì‹¤í–‰ ì‹œ í•„ìš”
- `.env.test`: `yarn test` ì‹¤í–‰ ì‹œ í•„ìš”

### Node.js ì„œë²„ ì‹¤í–‰

Node.js ì„œë²„ë¥¼ ì‹¤í–‰í•˜ëŠ” ë°©ë²•ì€ ì•„ë˜ì™€ ê°™ì´ 3ê°€ì§€ ìˆìŠµë‹ˆë‹¤.

1. Nodemonìœ¼ë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```
yarn dev
```

2. esbuild íŒ¨í‚¤ì§€ë¡œ ë²ˆë“¤ë§ í›„ Node.jsë¡œ ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```
yarn start
```

3. Docker í™˜ê²½ì—ì„œ Node.js ì„œë²„, PostgreSQL ì„œë²„, Redis ì„œë²„ë¥¼ ì‹¤í–‰í•©ë‹ˆë‹¤.

```
docker compose --env-file .env.local.docker up --detach --build --force-recreate
```

### CI/CD

GitHubì— push í•  ë•Œë§ˆë‹¤ ìë™ìœ¼ë¡œ `Cloud Build`ì—ì„œ ìƒˆë¡œìš´ Docker ì´ë¯¸ì§€ë¥¼ ë§Œë“¤ì–´ì„œ `Container Registry`ì— ì €ì¥í•©ë‹ˆë‹¤. ê·¸ë¦¬ê³  `Cloud Run`ì— ìš”ì²­ì´ ë“¤ì–´ì˜¤ë©´ ìƒˆë¡œìš´ ì´ë¯¸ì§€ë¥¼ ê¸°ë°˜ìœ¼ë¡œ Docker ì»¨í…Œì´ë„ˆë¥¼ ìƒì„±í•©ë‹ˆë‹¤.

## ğŸ‘¨â€ğŸ’» ê°œë°œ ê³¼ì •

### Yarn berry

> https://yarnpkg.com/getting-started/install

```bash
corepack enable
mkdir í´ë”ì´ë¦„
cd í´ë”ì´ë¦„
yarn init -2
```

### Git

> https://www.toptal.com/developers/gitignore

`.gitignore` íŒŒì¼ì„ ìƒì„±í•˜ê³  ì ì ˆíˆ ìˆ˜ì •í•©ë‹ˆë‹¤.

`.gitattributes` íŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì´ ìƒì„±í•©ë‹ˆë‹¤:

```
# Auto detect text files and perform LF normalization
* text eol=lf

# These files are binary and should be left untouched
*.png binary
*.jpg binary
*.jpeg binary
*.gif binary
*.ico binary
*.webp binary
*.pdf binary

*.otf binary
*.ttf binary
*.woff binary
*.woff2 binary

ê·¸ì™¸ ë°”ì´ë„ˆë¦¬ë¡œ ì·¨ê¸‰í•  íŒŒì¼ ëª©ë¡
```

### package.json

> https://docs.npmjs.com/cli/v8/configuring-npm/package-json

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "name": "í”„ë¡œì íŠ¸ ì´ë¦„",
  "version": "í”„ë¡œì íŠ¸ ë²„ì „",
  "description": "í”„ë¡œì íŠ¸ ì„¤ëª…",
  "homepage": "í™ˆí˜ì´ì§€ ì£¼ì†Œ",
  "bugs": {
    "url": "ë²„ê·¸ ì œë³´ ì£¼ì†Œ",
    "email": "ë²„ê·¸ ì œë³´ ì´ë©”ì¼"
  },
  "license": "ë¼ì´ì„ ìŠ¤",
  "author": "ê°œë°œì",
  "main": "í”„ë¡œê·¸ë¨ ì§„ì…ì  íŒŒì¼ ê²½ë¡œ",
  "repository": "ì €ì¥ì†Œ ì£¼ì†Œ",
  "scripts": {
    // ...
  },
  "dependencies": {
    // ...
  },
  "devDependencies": {
    // ...
  },
  "engines": {
    "node": ">=18.2.0"
  },
  "private": true,
  "packageManager": "yarn@3.3.0"
}
```

### TypeScript

> https://www.typescriptlang.org/download \
> https://stackoverflow.com/questions/72380007/what-typescript-configuration-produces-output-closest-to-node-js-18-capabilities/72380008#72380008

```bash
yarn add --dev typescript
yarn tsc --init
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  // ...
  "type": "module"
}
```

`tsconfig.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "compilerOptions": {
    // ...
    "allowSyntheticDefaultImports": true,
    "lib": ["ES2022"],
    "module": "ES2022",
    "moduleResolution": "node",
    "target": "ES2022"
  }
}
```

### Prettier

> https://prettier.io/docs/en/install.html

Prettierë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
yarn add --dev --exact prettier
echo {}> .prettierrc.json
```

`.prettierrc.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "printWidth": 100,
  "semi": false,
  "singleQuote": true
}
```

`.prettierignore` íŒŒì¼ì„ ì•„ë˜ì™€ ê°™ì´ ìƒì„±í•©ë‹ˆë‹¤:

```
.yarn
.pnp.*
```

### ESLint

> https://eslint.org/docs/latest/user-guide/getting-started \
> https://github.com/standard/eslint-config-standard \
> https://github.com/import-js/eslint-plugin-import \
> https://github.com/weiran-zsd/eslint-plugin-node#readme \
> https://github.com/xjamundx/eslint-plugin-promise \

```bash
npm init @eslint/config -- --config standard
âœ” How would you like to use ESLint? Â· style
âœ” What type of modules does your project use? Â· esm
âœ” Which framework does your project use? Â· none
âœ” Does your project use TypeScript? Â· No / Yes
âœ” Where does your code run? Â· node
âœ” How would you like to define a style for your project? Â· guide
âœ” Which style guide do you want to follow? Â· standard
âœ” What format do you want your config file to be in? Â· JSON
Checking peerDependencies of eslint-config-standard@latest
Local ESLint installation not found.
The config that you've selected requires the following dependencies:

@typescript-eslint/eslint-plugin@latest eslint-config-standard@latest eslint@^8.0.1 eslint-plugin-import@^2.25.2 eslint-plugin-n@^15.0.0 eslint-plugin-promise@^6.0.0 @typescript-eslint/parser@latest
âœ” Would you like to install them now? Â· No

yarn add --dev @typescript-eslint/eslint-plugin@latest eslint-config-standard@latest eslint@^8.0.1 eslint-plugin-import@^2.25.2 eslint-plugin-n@^15.0.0 eslint-plugin-promise@^6.0.0 @typescript-eslint/parser@latest
```

`eslintrc.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "env": {
    "es2022": true,
    "node": true
  },
  "extends": [
    "eslint:recommended",
    "plugin:import/recommended",
    "plugin:import/typescript",
    "plugin:n/recommended",
    "plugin:promise/recommended",
    "plugin:@typescript-eslint/recommended",
    "standard"
  ]
  // ...
}
```

### ESLint + (Prettier, Jest)

> https://github.com/prettier/eslint-config-prettier \
> https://github.com/jest-community/eslint-plugin-jest

```bash
yarn add --dev eslint eslint-plugin-jest eslint-config-prettier
```

`eslintrc.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "env": {
    // ...
    "jest/globals": true
  },
  "extends": [
    // ...
    // Make sure to put "prettier" last, so it gets the chance to override other configs
    "prettier"
  ],
  "overrides": [
    {
      "extends": ["plugin:jest/all"],
      "files": ["test/**"],
      "rules": {
        "jest/prefer-expect-assertions": "off"
      }
    }
  ]
  // ...
}
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "lint": "eslint . --fix --ignore-path .gitignore",
    "format": "prettier . --write"
    // ...
  }
  // ...
}
```

### Yarn berry + (ESLint, Prettier, TypeScript, VSCode, Next.js)

> https://yarnpkg.com/getting-started/editor-sdks \
> https://yarnpkg.com/cli/upgrade-interactive

```bash
yarn dlx @yarnpkg/sdks vscode
yarn plugin import interactive-tools
```

### Husky

> https://typicode.github.io/husky/#/?id=automatic-recommended \
> https://typicode.github.io/husky/#/?id=yarn-on-windows

Huskyë¥¼ ì„¤ì¹˜í•©ë‹ˆë‹¤.

```bash
yarn dlx husky-init --yarn2 && yarn
```

`.husky/common.sh` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```sh
command_exists () {
  command -v "$1" >/dev/null 2>&1
}

# Workaround for Windows 10, Git Bash and Yarn
if command*exists winpty && test -t 1; then
  exec < /dev/tty
fi
```

`.husky/pre-push` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```sh
#!/usr/bin/env sh
. "$(dirname -- "$0")/*/husky.sh"
. "$(dirname -- "$0")/common.sh"

yarn tsc
```

### VSCode

`.vscode/settings.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "editor.defaultFormatter": "esbenp.prettier-vscode",
  "editor.formatOnPaste": true,
  "editor.formatOnSave": true,
  "editor.insertSpaces": true,
  "editor.tabSize": 2,
  "files.autoSave": "onFocusChange",
  "files.eol": "\n",
  "sort-imports.default-sort-style": "module"

  // ...
}
```

`.vscode/recommendations.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "recommendations": [
    "visualstudioexptteam.vscodeintellicode",
    "christian-kohler.npm-intellisense",
    "christian-kohler.path-intellisense",
    "tabnine.tabnine-vscode",
    "amatiasq.sort-imports",
    "ms-azuretools.vscode-docker",
    "bradymholt.pgformatter",
    "foxundermoon.shell-format",
    "ckolkman.vscode-postgres"

    // ...
  ]
}
```

### Environment variables

> https://github.com/motdotla/dotenv

```bash
yarn add dotenv
```

ì•„ë˜ íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

| íŒŒì¼ ì´ë¦„           | `NODE_ENV`  | í™˜ê²½     | ìš©ë„            |
| ------------------- | ----------- | -------- | --------------- |
| `.env`              | production  | í´ë¼ìš°ë“œ | ì‹¤ ì„œë²„         |
| `.env.dev`          | production  | í´ë¼ìš°ë“œ | ìŠ¤í…Œì´ì§• ì„œë²„   |
| `.env.local`        | production  | ë¡œì»¬     | ì½”ë“œ ì¶•ì†Œ       |
| `.env.local.dev`    | development | ë¡œì»¬     | Fast refresh    |
| `.env.local.docker` | production  | ë¡œì»¬     | Docker ì»¨í…Œì´ë„ˆ |

`src/common/constants.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
// ìë™
export const NODE_ENV = process.env.NODE_ENV as string
export const K_SERVICE = process.env.K_SERVICE as string // GCPì—ì„œ ì‹¤í–‰ ì¤‘ì¼ ë•Œ
export const PORT = (process.env.PORT ?? '4000') as string

// ê³µí†µ
export const PROJECT_ENV = (process.env.PROJECT_ENV ?? '') as string
export const JWT_SECRET_KEY = process.env.JWT_SECRET_KEY as string

if (!PROJECT_ENV) throw new Error('`PROJECT_ENV` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
if (!JWT_SECRET_KEY) throw new Error('`JWT_SECRET_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')

// ê°œë³„
export const LOCALHOST_HTTPS_KEY = process.env.LOCALHOST_HTTPS_KEY as string
export const LOCALHOST_HTTPS_CERT = process.env.LOCALHOST_HTTPS_CERT as string

if (PROJECT_ENV.startsWith('local')) {
  if (!LOCALHOST_HTTPS_KEY) throw new Error('`LOCALHOST_HTTPS_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
  if (!LOCALHOST_HTTPS_CERT) throw new Error('`LOCALHOST_HTTPS_CERT` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
}
```

### Nodemon

> https://github.com/remy/nodemon

```bash
yarn add --dev nodemon
```

`nodemon.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "ext": "cjs",
  "watch": ["out"]
}
```

### esbuild

> https://esbuild.github.io/getting-started/#bundling-for-node \
> https://esbuild.github.io/api/#metafile \
> https://stackoverflow.com/a/35455532/16868717 \

```bash
yarn add --dev esbuild
```

`esbuild.js` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```js
import esbuild from 'esbuild'

const NODE_ENV = process.env.NODE_ENV

esbuild
  .build({
    bundle: true,
    entryPoints: ['src/index.ts'],
    loader: {
      '.sql': 'text',
    },
    metafile: true,
    minify: NODE_ENV === 'production',
    outfile: 'out/index.cjs',
    platform: 'node',
    target: ['node18'],
    treeShaking: true,
    watch: NODE_ENV === 'development' && {
      onRebuild: (error, result) => {
        if (error) {
          console.error('watch build failed:', error)
        } else {
          showOutfilesSize(result)
        }
      },
    },
  })
  .then((result) => showOutfilesSize(result))
  .catch((error) => {
    throw new Error(error)
  })

function showOutfilesSize(result) {
  const outputs = result.metafile.outputs
  for (const output in outputs) {
    console.log(`${output}: ${(outputs[output].bytes / 1_000_000).toFixed(2)} MB`)
  }
}
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "dev": "NODE_ENV=development node esbuild.js & NODE_ENV=development nodemon -r dotenv/config out/index.cjs dotenv_config_path=.env.local.dev",
    "build": "NODE_ENV=production node esbuild.js",
    "start": "yarn build && NODE_ENV=production node -r dotenv/config out/index.cjs dotenv_config_path=.env.local"
    // ...
  }
  // ...
}
```

`src/global-env.d.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
declare module '*.sql' {
  const content: string
  export default content
}
```

### Fastify

> https://www.fastify.io/docs/latest/Guides/Getting-Started/ \

```bash
yarn add fastify
```

`src/routes/index.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import Fastify from 'fastify'

import { K_SERVICE, NODE_ENV, PORT, PROJECT_ENV } from '../common/constants'
import productRoute from './product'
import userRoute from './user'

const fastify = Fastify({
  logger: NODE_ENV === 'production',
})

fastify.register(productRoute)
fastify.register(userRoute)

export default async function startServer() {
  try {
    await fastify.listen({ port: +PORT, host: K_SERVICE ? '0.0.0.0' : 'localhost' })
  } catch (err) {
    fastify.log.error(err)
    throw new Error()
  }
}
```

`.vscode/typescript.code-snippets` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "Fastify Routes": {
    "prefix": "route",
    "body": [
      "import { FastifyInstance } from 'fastify'",
      "",
      "export default async function routes(fastify: FastifyInstance, options: object) {",
      "  fastify.get('/${TM_FILENAME_BASE}', async (request, reply) => {",
      "    return { hello: '${TM_FILENAME_BASE}' }",
      "  })",
      "}",
      ""
    ],
    "description": "Fastify Routes"
  }
}
```

`src/routes/product.ts` íŒŒì¼ì„ ìƒì„±í•˜ê³  `route` ë‹¨ì¶•ì–´ë¥¼ ì…ë ¥í•´ ì•„ë˜ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•©ë‹ˆë‹¤:

```ts
import { FastifyInstance } from 'fastify'

export default async function routes(fastify: FastifyInstance, options: object) {
  fastify.get('/product', async (request, reply) => {
    return { hello: 'product' }
  })
}
```

`src/routes/user.ts` íŒŒì¼ì„ ìƒì„±í•˜ê³  `route` ë‹¨ì¶•ì–´ë¥¼ ì…ë ¥í•´ ì•„ë˜ ì½”ë“œë¥¼ ìë™ ì™„ì„±í•©ë‹ˆë‹¤:

```ts
import { FastifyInstance } from 'fastify'

export default async function routes(fastify: FastifyInstance, options: object) {
  fastify.get('/user', async (request, reply) => {
    return { hello: 'user' }
  })
}
```

### Fastify + HTTP2

> https://www.fastify.io/docs/latest/Reference/HTTP2/

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import {
  // ...
  LOCALHOST_HTTPS_CERT,
  LOCALHOST_HTTPS_KEY,
  PROJECT_ENV,
} from '../common/constants'

const fastify = Fastify({
  // ...
  http2: true,
  ...(PROJECT_ENV.startsWith('local') && {
    https: {
      key: `-----BEGIN PRIVATE KEY-----\n${LOCALHOST_HTTPS_KEY}\n-----END PRIVATE KEY-----`,
      cert: `-----BEGIN CERTIFICATE-----\n${LOCALHOST_HTTPS_CERT}\n-----END CERTIFICATE-----`,
    },
  }),
})

// ...
```

HTTPS ì¸ì¦ì„œë¥¼ ìƒì„±í•©ë‹ˆë‹¤:

```bash

```

### Fastify + CORS

> https://github.com/fastify/fastify-cors

```bash
yarn add @fastify/cors
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import cors from '@fastify/cors'

// ...

fastify.register(cors, {
  origin: [
    'http://localhost:3000',
    // ...
  ],
})
```

### Fastify + Prevent DoS

> https://github.com/fastify/fastify-rate-limit

```bash
yarn add @fastify/rate-limit
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import rateLimit from '@fastify/rate-limit'

// ...

fastify.register(rateLimit, {
  ...(NODE_ENV === 'development' && {
    allowList: ['127.0.0.1'],
  }),
})
```

### Fastify + JWT

> https://github.com/fastify/fastify-jwt

```bash
yarn add @fastify/jwt
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import fastifyJWT from '@fastify/jwt'
import {
  // ...
  JWT_SECRET_KEY,
} from '../common/constants'

// ...

fastify.register(fastifyJWT, {
  secret: JWT_SECRET_KEY,
})

type QuerystringJWT = {
  Querystring: {
    jwt?: string
  }
}

fastify.addHook<QuerystringJWT>('onRequest', async (request, reply) => {
  const jwt = request.headers.authorization ?? request.query.jwt
  if (!jwt) return

  request.headers.authorization = jwt

  try {
    await request.jwtVerify()
  } catch (err) {
    reply.send(err)
  }
})
```

### Fastify + Schema

> https://www.fastify.io/docs/latest/Reference/Type-Providers/ \
> https://github.com/sinclairzx81/typebox \
> https://github.com/fastify/fastify-type-provider-typebox

```bash
yarn add @sinclair/typebox
yarn add --dev @fastify/type-provider-typebox
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import { TypeBoxTypeProvider } from '@fastify/type-provider-typebox'
import { Type } from '@sinclair/typebox'

// ...

const fastify = Fastify({
  // ...
}).withTypeProvider<TypeBoxTypeProvider>()

const schema = {
  schema: {
    querystring: Type.Object({
      foo: Type.Optional(Type.Number()),
      bar: Type.Optional(Type.String()),
    }),
    response: {
      200: Type.Object({
        hello: Type.String(),
        foo: Type.Optional(Type.Number()),
        bar: Type.Optional(Type.String()),
      }),
    },
  },
}

fastify.get('/', schema, async (request, _) => {
  const { foo, bar } = request.query
  return { hello: 'world', foo, bar }
})
```

### Fastify + Swagger

```bash
yarn add @fastify/swagger
```

### Fastify + Google Cloud File uploader

> https://github.com/fastify/fastify-multipart \
> https://github.com/googleapis/nodejs-storage#readme \
> https://cloud.google.com/storage/docs/reference/libraries#client-libraries-install-nodejs \
> https://cloud.google.com/storage/docs/uploading-objects-from-memory \
> https://cloud.google.com/storage/docs/streaming-uploads#code-samples

```bash
yarn add @fastify/multipart @google-cloud/storage
```

`src/routes/index.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
import multipart from '@fastify/multipart'

// ..

fastify.register(multipart, {
  limits: {
    fileSize: 10_000_000,
    fieldSize: 1_000,
    files: 10,
  },
})
```

`src/routes/upload.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import { randomUUID } from 'crypto'
import path from 'path'

import { FastifyInstance } from 'fastify'

import { bucket } from '../common/google-storage'

type UploadResult = {
  fileName: string
  url: string
}

export default async function routes(fastify: FastifyInstance) {
  fastify.post('/upload/images', async function (request, reply) {
    // if (!request.userId) throw UnauthorizedError('ë¡œê·¸ì¸ í›„ ì‹œë„í•´ì£¼ì„¸ìš”')

    const files = request.files()
    const result: UploadResult[] = []

    for await (const file of files) {
      if (file.file) {
        // if (!file.mimetype.startsWith('image/'))
        //   throw BadRequestError('ì´ë¯¸ì§€ íŒŒì¼ë§Œ ì—…ë¡œë“œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤')

        const timestamp = ~~(Date.now() / 1000)
        const fileExtension = path.extname(file.filename)
        const fileName = `${timestamp}-${randomUUID()}${fileExtension}`

        bucket
          .file(fileName)
          .save(await file.toBuffer())
          .then(() =>
            result.push({
              fileName: file.filename,
              url: `https://storage.googleapis.com/${bucket.name}/${fileName}`,
            })
          )
          .catch((error) => console.log(error))
      }
    }

    reply.status(201).send(result)
  })
}
```

`src/common/constants.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
// ...

export const GOOGLE_CLOUD_STORAGE_BUCKET_NAME = process.env
  .GOOGLE_CLOUD_STORAGE_BUCKET_NAME as string
```

### PostgreSQL

> https://node-postgres.com/ \
> https://pgtyped.vercel.app/docs/cli \
> https://stackoverflow.com/a/20909045/16868717 \
> https://github.com/brianc/node-postgres/issues/2089

```bash
yarn add pg
yarn add --dev @types/pg @pgtyped/cli @pgtyped/query
```

`src/common/constants.ts` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```ts
// ...
export const POSTGRES_CA = process.env.POSTGRES_CA as string
export const POSTGRES_CERT = process.env.POSTGRES_CERT as string
export const POSTGRES_KEY = process.env.POSTGRES_KEY as string

if (PROJECT_ENV.startsWith('cloud') || PROJECT_ENV === 'local-prod') {
  if (!POSTGRES_CA) throw new Error('`POSTGRES_CA` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
  if (!POSTGRES_CERT) throw new Error('`POSTGRES_CERT` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
  if (!POSTGRES_KEY) throw new Error('`POSTGRES_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')

  // ...
}
```

`src/common/postgres.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import pg from 'pg'

import { PGURI, POSTGRES_CA, POSTGRES_CERT, POSTGRES_KEY, PROJECT_ENV } from '../common/constants'

const { Pool } = pg

export const pool = new Pool({
  connectionString: PGURI,

  ...((PROJECT_ENV === 'cloud-dev' ||
    PROJECT_ENV === 'cloud-prod' ||
    PROJECT_ENV === 'local-prod') && {
    ssl: {
      ca: `-----BEGIN CERTIFICATE-----\n${POSTGRES_CA}\n-----END CERTIFICATE-----`,
      key: `-----BEGIN PRIVATE KEY-----\n${POSTGRES_KEY}\n-----END PRIVATE KEY-----`,
      cert: `-----BEGIN CERTIFICATE-----\n${POSTGRES_CERT}\n-----END CERTIFICATE-----`,
      checkServerIdentity: () => {
        return undefined
      },
    },
  }),
})
```

`src/index.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import { networkInterfaces } from 'os'

import { NODE_ENV, PGURI, PORT, REDIS_CONNECTION_STRING } from './common/constants'
import { pool } from './common/postgres'
import startServer from './routes'

const nets = networkInterfaces()

pool
  .query('SELECT CURRENT_TIMESTAMP')
  .then(({ rows }) =>
    console.log(
      `ğŸš… Connected to ${PGURI} at ${new Date(rows[0].current_timestamp).toLocaleString()}`
    )
  )
  .catch((error) => {
    throw new Error('Cannot connect to PostgreSQL server... ' + error)
  })

startServer()
  .then((url) => {
    console.log(`ğŸš€ Server ready at: ${url}`)
    if (NODE_ENV !== 'production' && nets.en0)
      console.log(`ğŸš€ On Your Network: http://${nets.en0[1].address}:${PORT}`)
  })
  .catch((error) => {
    throw new Error('Cannot start API server... ' + error)
  })
```

`pgtyped.config.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "transforms": [
    {
      "mode": "sql",
      "include": "**/*.sql",
      "emitTemplate": "{{dir}}/{{name}}.ts"
    }
  ],
  "srcDir": "src/"
}
```

`package.json` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤. `dev` ìŠ¤í¬ë¦½íŠ¸ê°€ ê¸¸ì–´ì§€ê¸° ë•Œë¬¸ì— ì•„ë˜ì²˜ëŸ¼ sh íŒŒì¼ë¡œ ë¶„ë¦¬í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "dev": "src/dev.sh"
    // ...
  }
  // ...
}
```

`.yarnrc.yml` íŒŒì¼ì„ ìˆ˜ì •í•©ë‹ˆë‹¤:

```yml
packageExtensions:
  pg@*:
    dependencies:
      pg-native: '*'
# ...
```

`src/dev.sh` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```
touch src/dev.sh
chmod +x src/dev.sh
```

```sh
#!/bin/sh
export $(grep -v '^#' .env.local.dev | xargs) && pgtyped --watch --config pgtyped.config.json &
sleep 2 && NODE_ENV=development node esbuild.js &
sleep 2 && NODE_ENV=development nodemon -r dotenv/config out/index.cjs dotenv_config_path=.env.local.dev
```

### PostgreSQL CSV

> https://www.postgresqltutorial.com/postgresql-tutorial/export-postgresql-table-to-csv-file/ \
> https://dba.stackexchange.com/q/137140 \
> https://github.com/brianc/node-pg-copy-streams

```bash
yarn add pg-copy-streams
yarn add --dev @types/pg-copy-streams
```

`database/index.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import dotenv from 'dotenv'
import pg from 'pg'

// í™˜ê²½ ë³€ìˆ˜ ì„¤ì •
const env = process.argv[2]
export let CSV_PATH: string

if (env === 'prod') {
  dotenv.config()
  CSV_PATH = 'prod'
} else if (env === 'dev') {
  dotenv.config({ path: '.env.development' })
  CSV_PATH = 'dev'
} else {
  dotenv.config({ path: '.env.development.local' })
  CSV_PATH = 'local'
}

const PROJECT_ENV = process.env.PROJECT_ENV as string
const PGURI = process.env.PGURI as string
const POSTGRES_CA = process.env.POSTGRES_CA as string

if (!PROJECT_ENV) throw new Error('`PROJECT_ENV` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
if (!PGURI) throw new Error('`PGURI` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
if (!POSTGRES_CA) throw new Error('`POSTGRES_CA` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')

console.log(PGURI)

// eslint-disable-next-line @typescript-eslint/no-var-requires, no-undef
export const pool: pg.Pool = require('../src/common/postgres')
```

`database/export.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
/* eslint-disable no-console */
import { createWriteStream, mkdirSync, rmSync } from 'fs'
import { exit } from 'process'

import pgCopy from 'pg-copy-streams'

import { CSV_PATH, pool } from './index.js'

const { to } = pgCopy

// í´ë” ë‹¤ì‹œ ë§Œë“¤ê¸°
rmSync(`database/data/${CSV_PATH}`, { recursive: true, force: true })
mkdirSync(`database/data/${CSV_PATH}`, { recursive: true })

let fileCount = 0

const client = await pool.connect()

const { rows } = await client.query('SELECT schema_name FROM information_schema.schemata')

for (const row of rows) {
  const schemaName = row.schema_name
  if (schemaName !== 'pg_catalog' && schemaName !== 'information_schema') {
    const { rows: rows2 } = await client.query(
      `SELECT tablename FROM pg_tables WHERE schemaname='${schemaName}'`
    )

    for (const row2 of rows2) {
      const tableName = row2.tablename
      fileCount += 1
      console.log(`ğŸ‘€ - ${schemaName}.${tableName}`)

      const csvPath = `database/data/${CSV_PATH}/${schemaName}.${tableName}.csv`
      const fileStream = createWriteStream(csvPath)

      const sql = `COPY ${schemaName}.${tableName} TO STDOUT WITH CSV DELIMITER ',' HEADER ENCODING 'UTF-8'`
      const stream = client.query(to(sql))
      stream.pipe(fileStream)

      stream.on('end', () => {
        fileCount -= 1
        if (fileCount === 0) {
          client.release()
          exit()
        }
      })
    }
  }
}
```

`database/import.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
/* eslint-disable no-console */
import { createReadStream, readFileSync } from 'fs'
import { exit } from 'process'
import { createInterface } from 'readline'

import pgCopy from 'pg-copy-streams'

import { CSV_PATH, pool } from './index.js'

const { from } = pgCopy

const client = await pool.connect()

try {
  console.log('BEGIN')
  await client.query('BEGIN')

  const initialization = readFileSync('database/initialization.sql', 'utf8').toString()
  await client.query(initialization)

  // í…Œì´ë¸” ìƒì„± ìˆœì„œì™€ ë™ì¼í•˜ê²Œ
  const tables = [
    // ...
  ]

  // GENERATED ALWAYS AS IDENTITY ì»¬ëŸ¼ì´ ìˆëŠ” í…Œì´ë¸”
  const sequenceTables = [
    // ...
  ]

  for (const table of tables) {
    console.log('ğŸ‘€ - table', table)

    try {
      const csvPath = `database/data/${CSV_PATH}/${table}.csv`
      const columns = await readFirstLine(csvPath)
      const fileStream = createReadStream(csvPath)

      const sql = `COPY ${table}(${columns}) FROM STDIN WITH CSV DELIMITER ',' HEADER ENCODING 'UTF-8'`
      const stream = client.query(from(sql))
      fileStream.pipe(stream)
    } catch (error) {
      console.log('ğŸ‘€ - error', error)
    }
  }

  for (const sequenceTable of sequenceTables) {
    console.log('ğŸ‘€ - sequenceTable', sequenceTable)

    client.query(`LOCK TABLE ${sequenceTable} IN EXCLUSIVE MODE`)
    client.query(
      `SELECT setval(pg_get_serial_sequence('${sequenceTable}', 'id'), COALESCE((SELECT MAX(id)+1 FROM ${sequenceTable}), 1), false)`
    )
  }

  console.log('COMMIT')
  await client.query('COMMIT')
} catch (error) {
  console.log('ROLLBACK')
  await client.query('ROLLBACK')
  throw error
} finally {
  client.release()
}

exit()

// Utils
async function readFirstLine(path: string) {
  const inputStream = createReadStream(path)
  // eslint-disable-next-line no-unreachable-loop
  for await (const line of createInterface(inputStream)) return line
  inputStream.destroy()
}
```

`database/tsconfig.json` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```json
{
  "compilerOptions": {
    "target": "ES2022",
    "lib": ["ES2022"],
    "module": "ES2020",
    "moduleResolution": "node",
    "outDir": "dist",
    "allowSyntheticDefaultImports": true,
    "esModuleInterop": true,
    "forceConsistentCasingInFileNames": true,
    "strict": true,
    "skipLibCheck": true
  },
  "include": ["../"]
}
```

`package.json` íŒŒì¼ì˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ ìˆ˜ì •í•©ë‹ˆë‹¤:

```json
{
  "scripts": {
    "export": "tsc --project database/tsconfig.json && node database/dist/export.js",
    "import": "tsc --project database/tsconfig.json && node database/dist/import.js"
    // ...
  }
  // ...
}
```

### Redis

> https://github.com/redis/node-redis

`src/common/redis.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
import { createClient } from 'redis'

import {
  PROJECT_ENV,
  REDIS_CA,
  REDIS_CLIENT_CERT,
  REDIS_CLIENT_KEY,
  REDIS_CONNECTION_STRING,
} from '../common/constants'

export const redisClient = createClient({
  url: REDIS_CONNECTION_STRING,

  ...((PROJECT_ENV === 'cloud-dev' ||
    PROJECT_ENV === 'cloud-prod' ||
    PROJECT_ENV === 'local-prod') && {
    socket: {
      tls: true,
      ca: `-----BEGIN CERTIFICATE-----\n${REDIS_CA}\n-----END CERTIFICATE-----`,
      key: `-----BEGIN PRIVATE KEY-----\n${REDIS_CLIENT_KEY}\n-----END PRIVATE KEY-----`,
      cert: `-----BEGIN CERTIFICATE-----\n${REDIS_CLIENT_CERT}\n-----END CERTIFICATE-----`,
      checkServerIdentity: () => {
        return undefined
      },
      reconnectStrategy: (retries) => Math.min(retries * 1000, 15_000),
    },
  }),
})

redisClient.on('error', (err) => console.log('Redis Client Error', err))

export async function startRedisClient() {
  await redisClient.connect()
  return redisClient.time()
}
```

`src/common/constants.ts` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```ts
// ...
export const REDIS_CA = process.env.REDIS_CA as string
export const REDIS_CLIENT_KEY = process.env.REDIS_CLIENT_KEY as string
export const REDIS_CLIENT_CERT = process.env.REDIS_CLIENT_CERT as string

if (PROJECT_ENV.startsWith('cloud') || PROJECT_ENV === 'local-prod') {
  // ...

  if (!REDIS_CA) throw new Error('`REDIS_CA` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
  if (!REDIS_CLIENT_KEY) throw new Error('`REDIS_CLIENT_KEY` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
  if (!REDIS_CLIENT_CERT) throw new Error('`REDIS_CLIENT_CERT` í™˜ê²½ ë³€ìˆ˜ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”.')
}
```

### Docker

> https://docs.docker.com/engine/reference/builder/

`Dockerfile` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```dockerfile
# Install all packages and transpile TypeScript into JavaScript
FROM node:18-alpine AS builder

ENV NODE_ENV=production

WORKDIR /app

COPY .yarn .yarn
COPY .yarnrc.yml package.json yarn.lock ./
RUN yarn

COPY esbuild.js tsconfig.json ./
COPY src src
RUN yarn build

# Copy bundle only
FROM node:18-alpine AS runner

EXPOSE $PORT

ENV NODE_ENV=production

WORKDIR /app

COPY --from=builder /app/out out

ENTRYPOINT ["node", "out/index.cjs"]
```

### Docker Compose

> https://docs.docker.com/compose/reference/

`compose.yaml` íŒŒì¼ì„ ìƒì„±í•©ë‹ˆë‹¤:

```yml
services:
  yeou-backend:
    build: .
    container_name: yeou-api
    depends_on:
      - redis
      - postgres
    env_file: .env.docker.local
    image: yeou-api:latest
    restart: on-failure
    ports:
      - 4002:4002

  redis:
    image: redis:7-alpine
    command: redis-server --loglevel warning
    container_name: yeou-redis
    ports:
      - 6379
    restart: on-failure
    volumes:
      - 'redis:/data'

  postgres:
    image: postgres:14-alpine
    container_name: yeou-postgres
    environment:
      POSTGRES_PASSWORD: example
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - 5432
    restart: on-failure
    volumes:
      - 'postgres:/var/lib/postgresql/data'

  postgres-archive:
    image: postgres:14-alpine
    container_name: yeou-postgres-archive
    environment:
      POSTGRES_PASSWORD: example2
      POSTGRES_HOST_AUTH_METHOD: trust
    ports:
      - 54321
    restart: on-failure
    volumes:
      - 'postgres-archive:/var/lib/postgresql/data'

volumes:
  redis:
  postgres:
  postgres-archive:
```

### Cloud

Oracle cloud

Instance ìƒì„±

Ingress rule ì¶”ê°€: 5432, 6379

```bash

```

### OAuth

### Jest ?
